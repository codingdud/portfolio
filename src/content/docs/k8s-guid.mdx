---
title: ☸️ Complete Kubernetes Guide From Beginner to Advanced
description: This guide is designed to take you from a complete beginner to confidently deploying and managing applications on a Kubernetes cluster.
---

## Essential kubectl Commands - Quick Start

### Command Structure
```bash
kubectl [command] [TYPE] [NAME] [flags]
```

### Most Used Daily Commands
```bash
# Cluster and Node Information
kubectl cluster-info                    # Get cluster info
kubectl get nodes                      # List all nodes
kubectl describe node <node-name>      # Detailed node info

# Pod Management (The Basics)
kubectl get pods                       # List pods in current namespace
kubectl get pods --all-namespaces     # List pods in all namespaces
kubectl get pods -o wide              # List pods with extra info (IP, node)
kubectl describe pod <pod-name>       # Detailed pod information
kubectl logs <pod-name>               # Get pod logs
kubectl logs <pod-name> -f            # Follow/stream logs
kubectl logs <pod-name> --previous    # Get logs from previous container instance
kubectl exec -it <pod-name> -- bash   # Execute interactive shell in pod
kubectl delete pod <pod-name>         # Delete a pod
```

### Creating and Managing Resources
```bash
# Quick Resource Creation (Imperative)
kubectl run <pod-name> --image=<image-name> --restart=Never  # Create pod
kubectl create deployment <name> --image=<image-name>        # Create deployment
kubectl create service clusterip <name> --tcp=<port>:<target-port>  # Create service

# File-Based Management (Declarative - Recommended)
kubectl apply -f <file.yaml>           # Create/update resources from file
kubectl apply -f <directory>/          # Apply all YAML files in directory
kubectl delete -f <file.yaml>          # Delete resources defined in file
kubectl diff -f <file.yaml>            # Show differences before applying
```

### Scaling and Updates
```bash
kubectl scale deployment <name> --replicas=3              # Scale deployment
kubectl set image deployment/<name> <container>=<image>   # Update image
kubectl rollout status deployment/<name>                  # Check rollout status
kubectl rollout history deployment/<name>                 # View rollout history
kubectl rollout undo deployment/<name>                    # Rollback deployment
```

### Service Exposure and Networking
```bash
# Expose Deployments
kubectl expose deployment <name> --type=LoadBalancer --port=80
kubectl expose deployment <name> --type=NodePort --port=80
kubectl expose deployment <name> --type=ClusterIP --port=80

# Port Forwarding (for testing)
kubectl port-forward pod/<pod-name> 8080:80
kubectl port-forward service/<service-name> 8080:80
kubectl port-forward deployment/<deployment-name> 8080:80

# Service Discovery
kubectl get services                   # List services
kubectl get endpoints                  # List service endpoints
kubectl describe service <name>       # Detailed service info
```

### Debugging and Troubleshooting
```bash
# Essential Debug Commands
kubectl get events --sort-by=.metadata.creationTimestamp  # Recent cluster events
kubectl get all --all-namespaces      # Overview of all resources
kubectl top nodes                     # Node resource usage (needs metrics-server)
kubectl top pods                      # Pod resource usage

# Create Debug Pod
kubectl run debug --image=busybox --rm -it --restart=Never -- sh
kubectl run netshoot --image=nicolaka/netshoot --rm -it --restart=Never -- bash

# Copy Files
kubectl cp <pod-name>:/path/to/file ./local-file
kubectl cp ./local-file <pod-name>:/path/to/file
```

### Configuration and Context Management
```bash
kubectl config get-contexts           # List available contexts
kubectl config current-context       # Show current context
kubectl config use-context <name>    # Switch context
kubectl config set-context --current --namespace=<namespace>  # Set default namespace
```

### Resource Discovery and Help
```bash
# API Discovery
kubectl api-resources                 # List all resource types
kubectl api-versions                 # List API versions
kubectl explain <resource>           # Get resource documentation
kubectl explain pod.spec             # Get specific field documentation
kubectl explain deployment.spec.template.spec.containers --recursive

# Generate Resource Templates (Dry Run)
kubectl create deployment nginx --image=nginx --dry-run=client -o yaml
kubectl expose deployment nginx --port=80 --dry-run=client -o yaml
kubectl create configmap app-config --from-literal=key=value --dry-run=client -o yaml
```

### Advanced Operations
```bash
# Namespace Management
kubectl create namespace <name>       # Create namespace
kubectl get namespaces               # List namespaces
kubectl delete namespace <name>      # Delete namespace

# Label and Annotation Management
kubectl label pods <pod-name> app=web          # Add label
kubectl annotate pods <pod-name> description="Web server"  # Add annotation
kubectl get pods -l app=web          # Filter by label
kubectl get pods --show-labels       # Show all labels

# Resource Management
kubectl get <resource> -o json        # JSON output
kubectl get <resource> -o yaml        # YAML output
kubectl get <resource> -o wide        # Extended output
kubectl get <resource> --watch        # Watch for changes
```

### Helm Package Manager
```bash
# Helm Installation and Repo Management
helm repo add bitnami https://charts.bitnami.com/bitnami
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update                      # Update repositories

# Chart Operations
helm search repo <keyword>            # Search for charts
helm show values <chart-name>         # Show default values
helm install <release-name> <chart>   # Install chart
helm upgrade <release-name> <chart>   # Upgrade release
helm list                            # List releases
helm uninstall <release-name>        # Remove release
helm rollback <release-name> <revision>  # Rollback release

# Example Installations
helm install nginx bitnami/nginx
helm install prometheus prometheus-community/kube-prometheus-stack
helm install ingress-nginx ingress-nginx/ingress-nginx --namespace ingress-nginx --create-namespace
```

### Monitoring and Logging
```bash
# Advanced Logging
kubectl logs deployment/<name>        # Logs from deployment
kubectl logs -l app=<label>          # Logs from pods with label
kubectl logs <pod-name> -c <container>  # Multi-container pod logs
kubectl logs <pod-name> --tail=50    # Last 50 lines
kubectl logs <pod-name> --since=1h   # Logs from last hour

# Stern (Third-party tool for better log streaming)
stern <pod-pattern>                   # Stream logs from multiple pods
stern --namespace <ns> <pattern>      # Stream logs from specific namespace
```

### Warning: Dangerous Commands
```bash
# ⚠️ Use with extreme caution - these can destroy your cluster!
kubectl delete all --all --all-namespaces      # Delete all workloads
kubectl delete configmap --all --all-namespaces
kubectl delete secret --all --all-namespaces
kubectl delete pvc --all --all-namespaces      # Permanent data loss!
kubectl delete pv --all                        # Permanent data loss!
```

---

## What is Kubernetes?

**Kubernetes (K8s)** is like a smart conductor for your containerized applications. Think of it as:
- **Container Orchestrator**: Manages multiple containers across multiple machines
- **Auto-healer**: Restarts failed containers automatically
- **Load Balancer**: Distributes traffic across your applications
- **Resource Manager**: Efficiently uses CPU and memory across your cluster

### Why Use Kubernetes?
```bash
# Without Kubernetes: Manual container management
docker run -d my-app:v1
docker run -d my-app:v1  # Need to manually scale
# If container crashes, you need to manually restart

# With Kubernetes: Declarative management
kubectl apply -f deployment.yaml  # K8s handles scaling, healing, updates
```

---

## Getting Started

### Prerequisites
```bash
# Check if Docker is installed
docker --version

# Check if kubectl is installed
kubectl version --client

# Check if you have a cluster running
kubectl cluster-info
```

### Setting Up Your First Cluster

#### Option 1: Local Development (Minikube)
```bash
# Install minikube (on macOS)
brew install minikube

# Start your local cluster
minikube start

# Verify cluster is running
kubectl get nodes
```

#### Option 2: Cloud Provider
```bash
# AWS EKS
aws eks update-kubeconfig --region us-west-2 --name my-cluster

# Google GKE
gcloud container clusters get-credentials my-cluster --zone us-central1-a

# Azure AKS
az aks get-credentials --resource-group myResourceGroup --name myAKSCluster
```

### Common Setup Issues & Fixes

❌ **Problem**: `kubectl: command not found`
```bash
# Solution: Install kubectl
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
chmod +x kubectl
sudo mv kubectl /usr/local/bin/
```

❌ **Problem**: `The connection to the server localhost:8080 was refused`
```bash
# Solution: Check if cluster is running
minikube status
# If stopped, start it
minikube start

# Or check your kubeconfig
kubectl config current-context
kubectl config get-contexts
```

---

## Core Concepts

### 1. Pods - The Basic Unit

**What is a Pod?**
A Pod is the smallest deployable unit in Kubernetes. Think of it as a "wrapper" around one or more containers that share storage and network.

#### Simple Pod Example
```yaml
# simple-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-first-pod
  labels:
    app: hello-world
spec:
  containers:
  - name: hello-container
    image: nginx:latest
    ports:
    - containerPort: 80
```

```bash
# Create the pod
kubectl apply -f simple-pod.yaml

# Check if it's running
kubectl get pods
kubectl describe pod my-first-pod

# Test it
kubectl port-forward my-first-pod 8080:80
# Open browser to http://localhost:8080
```

#### Multi-Container Pod Example
```yaml
# multi-container-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: multi-container-pod
spec:
  containers:
  - name: web-server
    image: nginx
    ports:
    - containerPort: 80
    volumeMounts:
    - name: shared-storage
      mountPath: /usr/share/nginx/html
  - name: file-generator
    image: busybox
    command: ['sh', '-c']
    args:
    - while true; do
        echo "<h1>Hello from $(hostname)</h1><p>$(date)</p>" > /shared/index.html;
        sleep 30;
      done
    volumeMounts:
    - name: shared-storage
      mountPath: /shared
  volumes:
  - name: shared-storage
    emptyDir: {}
```

### 2. Deployments - Managing Pod Lifecycles

**Why use Deployments?**
- Manages multiple pod replicas
- Handles rolling updates
- Provides rollback capabilities
- Ensures desired state

#### Basic Deployment
```yaml
# basic-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3  # We want 3 pods
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.20
        ports:
        - containerPort: 80
        resources:
          requests:
            memory: "64Mi"
            cpu: "250m"
          limits:
            memory: "128Mi"
            cpu: "500m"
```

```bash
# Deploy it
kubectl apply -f basic-deployment.yaml

# Watch the rollout
kubectl rollout status deployment/nginx-deployment

# Scale up/down
kubectl scale deployment nginx-deployment --replicas=5

# Update the image (rolling update)
kubectl set image deployment/nginx-deployment nginx=nginx:1.21

# Check rollout history
kubectl rollout history deployment/nginx-deployment

# Rollback if needed
kubectl rollout undo deployment/nginx-deployment
```

### 3. Services - Networking Made Simple

**What is a Service?**
A Service provides stable networking for your pods. Even if pods get replaced, the Service IP stays the same.

#### Service Types Explained
- **ClusterIP** - Internal cluster access only (default)
- **NodePort** - External access via node port (30000-32767)
- **LoadBalancer** - Cloud provider load balancer
- **ExternalName** - DNS CNAME mapping

#### ClusterIP Service (Internal Access)
```yaml
# clusterip-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx  # Selects pods with this label
  ports:
  - protocol: TCP
    port: 80        # Service port
    targetPort: 80  # Pod port
  type: ClusterIP   # Default - internal access only
```

#### NodePort Service (External Access)
```yaml
# nodeport-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-nodeport
spec:
  selector:
    app: nginx
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
    nodePort: 30080  # Accessible on all nodes at this port
  type: NodePort
```

#### LoadBalancer Service (Cloud Provider)
```yaml
# loadbalancer-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-loadbalancer
spec:
  selector:
    app: nginx
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  type: LoadBalancer  # Cloud provider will create a load balancer
```

```bash
# Test your services
kubectl get services

# Test internal connectivity
kubectl run test-pod --image=busybox --rm -it --restart=Never -- sh
# Inside the pod:
# wget -qO- nginx-service  # Should return nginx default page

# For NodePort, access via: http://NODE_IP:30080
# For LoadBalancer, get external IP:
kubectl get service nginx-loadbalancer
```

### 4. ConfigMaps and Secrets

#### ConfigMap Example
```yaml
# app-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  database_url: "postgresql://db.example.com:5432"
  log_level: "info"
  feature_flags: |
    feature_a: true
    feature_b: false
  nginx.conf: |
    server {
        listen 80;
        location / {
            return 200 "Hello from ConfigMap!";
        }
    }
```

#### Secret Example
```yaml
# app-secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
type: Opaque
data:
  username: YWRtaW4=  # base64 encoded 'admin'
  password: cGFzc3dvcmQ=  # base64 encoded 'password'
```

```bash
# Create secret from command line
kubectl create secret generic app-secrets \
  --from-literal=username=admin \
  --from-literal=password=password

# Create secret from file
echo -n 'admin' > username.txt
kubectl create secret generic app-secrets --from-file=username.txt
```

#### Using ConfigMaps and Secrets in Pods
```yaml
# pod-with-config.yaml
apiVersion: v1
kind: Pod
metadata:
  name: app-with-config
spec:
  containers:
  - name: app
    image: busybox
    command: ['sh', '-c', 'env && sleep 3600']
    env:
    - name: DATABASE_URL
      valueFrom:
        configMapKeyRef:
          name: app-config
          key: database_url
    - name: USERNAME
      valueFrom:
        secretKeyRef:
          name: app-secrets
          key: username
    volumeMounts:
    - name: config-volume
      mountPath: /etc/config
  volumes:
  - name: config-volume
    configMap:
      name: app-config
```

### 5. Labels and Selectors

Labels are key-value pairs under `metadata:` used for selecting and organizing resources:
```yaml
metadata:
  labels:
    app: my-app
    version: v1.0
    environment: production
    tier: frontend
```

```bash
# Working with labels
kubectl label pods <pod-name> environment=production
kubectl get pods -l app=my-app
kubectl get pods -l environment=production,tier=frontend
kubectl delete pods -l environment=staging  # Delete pods with label
```

---

## Hands-on Examples

### Example 1: Complete Web Application

Let's deploy a complete web application with database, backend, and frontend.

#### Step 1: Database (MongoDB)
```yaml
# mongodb-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mongodb
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mongodb
  template:
    metadata:
      labels:
        app: mongodb
    spec:
      containers:
      - name: mongodb
        image: mongo:5.0
        ports:
        - containerPort: 27017
        env:
        - name: MONGO_INITDB_ROOT_USERNAME
          value: admin
        - name: MONGO_INITDB_ROOT_PASSWORD
          value: password123
        volumeMounts:
        - name: mongodb-storage
          mountPath: /data/db
      volumes:
      - name: mongodb-storage
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: mongodb-service
spec:
  selector:
    app: mongodb
  ports:
  - port: 27017
    targetPort: 27017
```

#### Step 2: Backend API
```yaml
# backend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend-api
spec:
  replicas: 2
  selector:
    matchLabels:
      app: backend-api
  template:
    metadata:
      labels:
        app: backend-api
    spec:
      containers:
      - name: api
        image: node:16-alpine
        ports:
        - containerPort: 3000
        env:
        - name: MONGODB_URI
          value: mongodb://admin:password123@mongodb-service:27017/myapp?authSource=admin
        - name: PORT
          value: "3000"
        command: ['sh', '-c']
        args:
        - |
          cat > server.js << 'EOF'
          const express = require('express');
          const app = express();
          const port = process.env.PORT || 3000;
          
          app.get('/api/health', (req, res) => {
            res.json({ status: 'healthy', timestamp: new Date() });
          });
          
          app.get('/api/info', (req, res) => {
            res.json({ 
              message: 'Hello from Backend!',
              mongodb: process.env.MONGODB_URI ? 'configured' : 'not configured'
            });
          });
          
          app.listen(port, () => {
            console.log(`Server running on port ${port}`);
          });
          EOF
          npm init -y
          npm install express
          node server.js
---
apiVersion: v1
kind: Service
metadata:
  name: backend-service
spec:
  selector:
    app: backend-api
  ports:
  - port: 3000
    targetPort: 3000
```

#### Step 3: Frontend
```yaml
# frontend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 2
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
    spec:
      containers:
      - name: nginx
        image: nginx:alpine
        ports:
        - containerPort: 80
        volumeMounts:
        - name: html-content
          mountPath: /usr/share/nginx/html
      volumes:
      - name: html-content
        configMap:
          name: frontend-content
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: frontend-content
data:
  index.html: |
    <!DOCTYPE html>
    <html>
    <head>
        <title>My K8s App</title>
        <style>
            body { font-family: Arial, sans-serif; margin: 40px; }
            .container { max-width: 600px; margin: 0 auto; }
            button { padding: 10px; margin: 5px; }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>Welcome to My Kubernetes App!</h1>
            <button onclick="checkHealth()">Check Backend Health</button>
            <button onclick="getInfo()">Get Backend Info</button>
            <div id="result"></div>
        </div>
        
        <script>
        function checkHealth() {
            fetch('/api/health')
                .then(response => response.json())
                .then(data => {
                    document.getElementById('result').innerHTML = 
                        '<h3>Health Check:</h3><pre>' + JSON.stringify(data, null, 2) + '</pre>';
                })
                .catch(error => {
                    document.getElementById('result').innerHTML = 
                        '<h3>Error:</h3><p>' + error + '</p>';
                });
        }
        
        function getInfo() {
            fetch('/api/info')
                .then(response => response.json())
                .then(data => {
                    document.getElementById('result').innerHTML = 
                        '<h3>Backend Info:</h3><pre>' + JSON.stringify(data, null, 2) + '</pre>';
                })
                .catch(error => {
                    document.getElementById('result').innerHTML = 
                        '<h3>Error:</h3><p>' + error + '</p>';
                });
        }
        </script>
    </body>
    </html>
---
apiVersion: v1
kind: Service
metadata:
  name: frontend-service
spec:
  selector:
    app: frontend
  ports:
  - port: 80
    targetPort: 80
  type: LoadBalancer
```

#### Step 4: Ingress for Routing
```yaml
# app-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: app-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - http:
      paths:
      - path: /api
        pathType: Prefix
        backend:
          service:
            name: backend-service
            port:
              number: 3000
      - path: /
        pathType: Prefix
        backend:
          service:
            name: frontend-service
            port:
              number: 80
```

#### Deploy the Complete Application
```bash
# Deploy everything
kubectl apply -f mongodb-deployment.yaml
kubectl apply -f backend-deployment.yaml
kubectl apply -f frontend-deployment.yaml

# Install ingress controller (if not already installed)
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.1/deploy/static/provider/cloud/deploy.yaml

# Deploy ingress
kubectl apply -f app-ingress.yaml

# Check everything is running
kubectl get all
kubectl get ingress

# Get the external IP (for LoadBalancer)
kubectl get service frontend-service
```

---

## Troubleshooting Guide

### Common Pod Issues

#### Issue 1: Pod Stuck in Pending State
```bash
# Check pod status
kubectl get pods
kubectl describe pod <pod-name>

# Common causes and fixes:
```

**Cause 1: Insufficient Resources**
```bash
# Check node resources
kubectl describe nodes
kubectl top nodes  # Requires metrics-server

# Solution: Add more nodes or reduce resource requests
```

**Cause 2: Image Pull Issues**
```yaml
# Wrong image name/tag
spec:
  containers:
  - name: app
    image: nginx:wrong-tag  # ❌ This will fail

# Fix: Use correct image
spec:
  containers:
  - name: app
    image: nginx:latest     # ✅ This works
```

**Cause 3: PVC Binding Issues**
```bash
# Check PVC status
kubectl get pvc
kubectl describe pvc <pvc-name>

# Check if StorageClass exists
kubectl get storageclass
```

#### Issue 2: Pod Crashes (CrashLoopBackOff)
```bash
# Get logs from crashed container
kubectl logs <pod-name> --previous

# Common fixes:
```

**Memory/CPU Limits Too Low**
```yaml
# Before (too restrictive)
resources:
  limits:
    memory: "64Mi"
    cpu: "100m"

# After (more reasonable)
resources:
  limits:
    memory: "256Mi"
    cpu: "500m"
  requests:
    memory: "128Mi"
    cpu: "250m"
```

**Wrong Command/Args**
```yaml
# Wrong
spec:
  containers:
  - name: app
    image: busybox
    command: ["/bin/bash"]  # busybox doesn't have bash

# Correct
spec:
  containers:
  - name: app
    image: busybox
    command: ["/bin/sh"]    # busybox has sh
```

#### Issue 3: Pod Can't Access Other Services

**DNS Resolution Test**
```bash
# Create debug pod
kubectl run debug --image=busybox --rm -it --restart=Never -- sh

# Inside the pod, test DNS
nslookup kubernetes.default.svc.cluster.local
nslookup <service-name>.<namespace>.svc.cluster.local

# Test connectivity
wget -qO- http://<service-name>:port
```

**Service Selector Mismatch**
```yaml
# Service
spec:
  selector:
    app: my-app    # Looking for pods with label app=my-app

# Pod (WRONG)
metadata:
  labels:
    name: my-app   # Has label name=my-app (won't match)

# Pod (CORRECT)
metadata:
  labels:
    app: my-app    # Has label app=my-app (will match)
```

### Network Troubleshooting

#### Debug Network Issues
```bash
# Create network debug pod
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: netshoot
spec:
  containers:
  - name: netshoot
    image: nicolaka/netshoot
    command: ['sleep', '3600']
EOF

# Use the debug pod
kubectl exec -it netshoot -- bash

# Inside netshoot, you can use:
# dig, nslookup, curl, wget, ping, traceroute, netstat, ss, etc.
```

#### Service Discovery Issues
```bash
# Check if service exists
kubectl get svc

# Check service endpoints
kubectl get endpoints <service-name>

# If no endpoints, check if pods have correct labels
kubectl get pods --show-labels
```

### Storage Issues

#### PVC Stuck in Pending
```bash
# Check PVC status
kubectl describe pvc <pvc-name>

# Common issues:
# 1. No default StorageClass
kubectl get storageclass

# 2. Insufficient storage
kubectl describe nodes | grep -A5 "Allocated resources"

# 3. Wrong access mode
# ReadWriteOnce: Can be mounted by single node
# ReadWriteMany: Can be mounted by multiple nodes
# ReadOnlyMany: Read-only by multiple nodes
```

#### Volume Mount Issues
```yaml
# Common mistake: Wrong mount path
volumeMounts:
- name: data-volume
  mountPath: /data/app  # Make sure this path exists in container

# Fix: Create directory or use existing path
volumeMounts:
- name: data-volume
  mountPath: /usr/share/nginx/html  # nginx serves from here
```

---

## Advanced Topics

### 1. Persistent Storage

#### Dynamic Volume Provisioning
```yaml
# storageclass.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: fast-ssd
provisioner: kubernetes.io/gce-pd  # For GKE
parameters:
  type: pd-ssd
  replication-type: none
allowVolumeExpansion: true
volumeBindingMode: WaitForFirstConsumer
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: app-storage
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: fast-ssd
  resources:
    requests:
      storage: 10Gi
```

#### StatefulSet with Persistent Storage
```yaml
# statefulset-with-storage.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: database
spec:
  serviceName: "database"
  replicas: 3
  selector:
    matchLabels:
      app: database
  template:
    metadata:
      labels:
        app: database
    spec:
      containers:
      - name: postgres
        image: postgres:13
        env:
        - name: POSTGRES_DB
          value: myapp
        - name: POSTGRES_USER
          value: user
        - name: POSTGRES_PASSWORD
          value: password
        volumeMounts:
        - name: data
          mountPath: /var/lib/postgresql/data
        ports:
        - containerPort: 5432
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: fast-ssd
      resources:
        requests:
          storage: 20Gi
```

### 2. Advanced Networking

#### Network Policies
```yaml
# network-policy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: api-network-policy
spec:
  podSelector:
    matchLabels:
      app: api
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: frontend
    ports:
    - protocol: TCP
      port: 3000
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: database
    ports:
    - protocol: TCP
      port: 5432
```

### 3. Security

#### Pod Security Standards
```yaml
# secure-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: secure-app
spec:
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    runAsGroup: 1000
    fsGroup: 1000
  containers:
  - name: app
    image: nginx:alpine
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      capabilities:
        drop:
        - ALL
    volumeMounts:
    - name: tmp
      mountPath: /tmp
    - name: var-cache
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
  volumes:
  - name: tmp
    emptyDir: {}
  - name: var-cache
    emptyDir: {}
  - name: var-run
    emptyDir: {}
```

#### RBAC (Role-Based Access Control)
```yaml
# rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: app-service-account
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: app-role
rules:
- apiGroups: [""]
  resources: ["pods", "services"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["apps"]
  resources: ["deployments"]
  verbs: ["get", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: app-role-binding
subjects:
- kind: ServiceAccount
  name: app-service-account
roleRef:
  kind: Role
  name: app-role
  apiGroup: rbac.authorization.k8s.io
```

### 4. Monitoring and Logging

#### Prometheus and Grafana with Helm
```bash
# Add Prometheus community repo
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# Install Prometheus stack (includes Grafana)
helm install monitoring prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --create-namespace \
  --set grafana.adminPassword=admin123

# Get Grafana admin password
kubectl get secret --namespace monitoring monitoring-grafana -o jsonpath="{.data.admin-password}" | base64 --decode

# Port forward to access Grafana
kubectl port-forward --namespace monitoring svc/monitoring-grafana 3000:80
# Access at http://localhost:3000 (username: admin)
```

#### Custom Metrics with ServiceMonitor
```yaml
# servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: app-metrics
  labels:
    app: my-app
spec:
  selector:
    matchLabels:
      app: my-app
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
```

#### Logging with ELK Stack
```bash
# Install Elasticsearch
helm repo add elastic https://helm.elastic.co
helm install elasticsearch elastic/elasticsearch \
  --set replicas=1 \
  --set minimumMasterNodes=1

# Install Kibana
helm install kibana elastic/kibana

# Install Filebeat for log collection
helm install filebeat elastic/filebeat
```

### 5. GitOps with ArgoCD

#### Install ArgoCD
```bash
# Install ArgoCD
kubectl create namespace argocd
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

# Get initial admin password
kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d

# Port forward to access ArgoCD UI
kubectl port-forward svc/argocd-server -n argocd 8080:443

# Access at https://localhost:8080 (username: admin)
```

#### ArgoCD Application
```yaml
# argocd-app.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: my-app
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/your-org/k8s-manifests
    targetRevision: HEAD
    path: production
  destination:
    server: https://kubernetes.default.svc
    namespace: my-app
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
```

---

## Best Practices

### 1. Resource Management

#### Always Set Resource Requests and Limits
```yaml
# Bad: No resource constraints
spec:
  containers:
  - name: app
    image: nginx

# Good: Proper resource management
spec:
  containers:
  - name: app
    image: nginx
    resources:
      requests:
        memory: "128Mi"
        cpu: "250m"
      limits:
        memory: "256Mi"
        cpu: "500m"
```

#### Use Horizontal Pod Autoscaler (HPA)
```yaml
# hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: app-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: my-app
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

#### Vertical Pod Autoscaler (VPA)
```yaml
# vpa.yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: app-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: my-app
  updatePolicy:
    updateMode: "Auto"  # "Off", "Initial", "Auto"
```

### 2. Health Checks

#### Comprehensive Health Checks
```yaml
# health-checks.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: web-app
  template:
    metadata:
      labels:
        app: web-app
    spec:
      containers:
      - name: app
        image: nginx
        ports:
        - containerPort: 80
        # Startup probe (for slow-starting containers)
        startupProbe:
          httpGet:
            path: /health
            port: 80
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 30  # 30 * 10 = 300 seconds max startup time
        # Liveness probe (restart container if fails)
        livenessProbe:
          httpGet:
            path: /health
            port: 80
          initialDelaySeconds: 60
          periodSeconds: 30
          timeoutSeconds: 5
          failureThreshold: 3
        # Readiness probe (remove from service if fails)
        readinessProbe:
          httpGet:
            path: /ready
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
```

### 3. Configuration Management

#### Use ConfigMaps and Secrets Properly
```yaml
# Bad: Hardcoded values
spec:
  containers:
  - name: app
    image: myapp:latest
    env:
    - name: DATABASE_URL
      value: "postgresql://user:password@db:5432/myapp"  # Hardcoded!

# Good: Use ConfigMaps and Secrets
spec:
  containers:
  - name: app
    image: myapp:latest
    envFrom:
    - configMapRef:
        name: app-config
    - secretRef:
        name: app-secrets
```

#### Environment-Specific Configurations with Kustomize
```bash
# Directory structure
k8s/
├── base/
│   ├── deployment.yaml
│   ├── service.yaml
│   └── kustomization.yaml
├── overlays/
│   ├── development/
│   │   ├── kustomization.yaml
│   │   └── config.yaml
│   ├── staging/
│   │   ├── kustomization.yaml
│   │   └── config.yaml
│   └── production/
│       ├── kustomization.yaml
│       └── config.yaml
```

```yaml
# base/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
- deployment.yaml
- service.yaml

# overlays/production/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

bases:
- ../../base

patchesStrategicMerge:
- config.yaml

images:
- name: myapp
  newTag: v1.2.3
```

```bash
# Deploy with Kustomize
kubectl apply -k overlays/production/
```

### 4. Security Best Practices

#### Pod Security Context
```yaml
# secure-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: secure-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: secure-app
  template:
    metadata:
      labels:
        app: secure-app
    spec:
      serviceAccountName: app-service-account  # Don't use default SA
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      containers:
      - name: app
        image: myapp:latest
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          capabilities:
            drop:
            - ALL
            add:
            - NET_BIND_SERVICE  # Only if needed
        volumeMounts:
        - name: tmp
          mountPath: /tmp
        - name: cache
          mountPath: /app/cache
      volumes:
      - name: tmp
        emptyDir: {}
      - name: cache
        emptyDir: {}
```

#### Network Policies
```yaml
# default-deny-all.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-all
spec:
  podSelector: {}  # Applies to all pods
  policyTypes:
  - Ingress
  - Egress
---
# allow-same-namespace.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-same-namespace
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: my-namespace
```

### 5. Debugging and Performance Tools

#### Essential Debug Toolkit
```yaml
# debug-toolkit.yaml
apiVersion: v1
kind: Pod
metadata:
  name: debug-toolkit
spec:
  containers:
  - name: debug
    image: nicolaka/netshoot
    command: ['sleep', '86400']  # 24 hours
    securityContext:
      capabilities:
        add: ["NET_ADMIN", "SYS_PTRACE"]
  restartPolicy: Never
```

#### Advanced Debugging Commands
```bash
# Network debugging
kubectl exec -it debug-toolkit -- tcpdump -i eth0

# DNS debugging
kubectl exec -it debug-toolkit -- dig kubernetes.default.svc.cluster.local

# Performance testing
kubectl exec -it debug-toolkit -- iperf3 -c service-name

# SSL/TLS debugging
kubectl exec -it debug-toolkit -- openssl s_client -connect service-name:443

# HTTP debugging with detailed output
kubectl exec -it debug-toolkit -- curl -v -H "Host: example.com" http://ingress-ip/
```

#### Cluster-wide Debugging
```bash
# Get all events sorted by time
kubectl get events --all-namespaces --sort-by='.lastTimestamp'

# Check cluster resource usage
kubectl top nodes
kubectl top pods --all-namespaces --sort-by=memory

# Check for failed pods across all namespaces
kubectl get pods --all-namespaces --field-selector=status.phase=Failed

# Get pod resource usage
kubectl describe nodes | grep -A5 "Allocated resources"

# Check API server logs
kubectl logs -n kube-system -l component=kube-apiserver

# Check scheduler logs
kubectl logs -n kube-system -l component=kube-scheduler
```

### 6. Backup and Disaster Recovery

#### Velero for Backup
```bash
# Install Velero
velero install \
    --provider aws \
    --plugins velero/velero-plugin-for-aws:v1.7.0 \
    --bucket my-backup-bucket \
    --secret-file ./credentials-velero

# Create backup
velero backup create my-backup --include-namespaces my-app

# Schedule regular backups
velero schedule create daily-backup \
    --schedule="0 2 * * *" \
    --include-namespaces my-app \
    --ttl 720h

# Restore from backup
velero restore create --from-backup my-backup
```

#### ETCD Backup (for self-managed clusters)
```bash
# Backup etcd
ETCDCTL_API=3 etcdctl snapshot save snapshot.db \
  --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/healthcheck-client.crt \
  --key=/etc/kubernetes/pki/etcd/healthcheck-client.key

# Verify backup
ETCDCTL_API=3 etcdctl --write-out=table snapshot status snapshot.db

# Restore etcd (in disaster recovery scenario)
ETCDCTL_API=3 etcdctl snapshot restore snapshot.db \
  --name=master \
  --data-dir=/var/lib/etcd-from-backup
```

### 7. Performance Optimization

#### Resource Optimization
```yaml
# performance-optimized.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: optimized-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: optimized-app
  template:
    metadata:
      labels:
        app: optimized-app
    spec:
      # Node affinity for better scheduling
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            preference:
              matchExpressions:
              - key: node-type
                operator: In
                values:
                - compute-optimized
        # Pod anti-affinity to spread pods across nodes
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - optimized-app
              topologyKey: kubernetes.io/hostname
      containers:
      - name: app
        image: myapp:latest
        resources:
          requests:
            memory: "256Mi"
            cpu: "500m"
          limits:
            memory: "512Mi"
            cpu: "1000m"
        # Optimize container startup
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 15"]  # Graceful shutdown
      # Optimize pod scheduling
      priorityClassName: high-priority
      terminationGracePeriodSeconds: 30
```

#### Priority Classes
```yaml
# priority-class.yaml
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: high-priority
value: 1000
globalDefault: false
description: "High priority class for critical applications"
---
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: low-priority
value: 100
globalDefault: false
description: "Low priority class for background jobs"
```

---

## CLI Quick Reference Card

### Emergency Commands
```bash
# Emergency pod deletion
kubectl delete pod <pod-name> --force --grace-period=0

# Drain node for maintenance
kubectl drain <node-name> --ignore-daemonsets --delete-emptydir-data

# Cordon node (prevent scheduling)
kubectl cordon <node-name>

# Uncordon node
kubectl uncordon <node-name>

# Emergency namespace deletion
kubectl delete namespace <namespace> --force --grace-period=0

# Get cluster info dump
kubectl cluster-info dump --output-directory=/tmp/cluster-dump
```

### Performance and Monitoring
```bash
# Resource usage
kubectl top nodes --sort-by=memory
kubectl top pods --all-namespaces --sort-by=cpu

# Resource quotas
kubectl describe quota --all-namespaces

# Network policies
kubectl get networkpolicies --all-namespaces

# Storage
kubectl get pv,pvc --all-namespaces
kubectl describe storageclass
```

### One-liners for Common Tasks
```bash
# Get all failing pods
kubectl get pods --all-namespaces --field-selector=status.phase!=Running

# Get pods by node
kubectl get pods --all-namespaces -o wide --sort-by="{.spec.nodeName}"

# Get all images in use
kubectl get pods --all-namespaces -o jsonpath="{.items[*].spec.containers[*].image}" | tr -s '[[:space:]]' '\n' | sort | uniq -c

# Get all pods using a specific service account
kubectl get pods --all-namespaces -o jsonpath='{range .items[?(@.spec.serviceAccountName=="my-sa")]}{.metadata.name}{" "}{.metadata.namespace}{"\n"}{end}'

# Find pods consuming most CPU/Memory
kubectl top pods --all-namespaces --sort-by=cpu
kubectl top pods --all-namespaces --sort-by=memory

# Get all pods with their restart count
kubectl get pods --all-namespaces --sort-by="{.status.containerStatuses[0].restartCount}"
```

---

## Next Steps

### Learn More About:
1. **Service Mesh**: Istio, Linkerd for advanced traffic management
2. **GitOps**: ArgoCD, Flux for automated deployments
3. **Monitoring**: Prometheus, Grafana, Jaeger for observability
4. **Security**: Falco, OPA Gatekeeper for policy enforcement
5. **CI/CD**: Tekton, Jenkins X for pipeline automation
6. **Serverless**: Knative, OpenFaaS for event-driven computing

### Recommended Learning Path:
1. Master basic concepts (Pods, Deployments, Services)
2. Learn storage and configuration management
3. Understand networking and security
4. Practice troubleshooting skills
5. Explore advanced topics (service mesh, monitoring)
6. Implement GitOps workflows

### Useful Resources:
- [Official Kubernetes Documentation](https://kubernetes.io/docs/)
- [Kubernetes The Hard Way](https://github.com/kelseyhightower/kubernetes-the-hard-way)
- [CNCF Landscape](https://landscape.cncf.io/)
- [Kubernetes Slack](https://kubernetes.slack.com/)

---

## When Things Go Wrong

### Emergency Checklist:
1. Check if cluster nodes are healthy: `kubectl get nodes`
2. Check if pods are running: `kubectl get pods --all-namespaces`
3. Check recent events: `kubectl get events --sort-by=.metadata.creationTimestamp`
4. Check resource usage: `kubectl top nodes && kubectl top pods`
5. Check logs: `kubectl logs <pod-name> --previous`

### Common Issues Quick Fix:
```bash
# Pod stuck in Pending
kubectl describe pod <pod-name> | grep Events -A 10

# Pod stuck in CrashLoopBackOff
kubectl logs <pod-name> --previous

# Service not accessible
kubectl get endpoints <service-name>

# Ingress not working
kubectl describe ingress <ingress-name>

# Storage issues
kubectl describe pvc <pvc-name>
```

Remember: Every Kubernetes expert was once a beginner. The key to mastering Kubernetes is practice, patience, and persistence. Start with simple examples, gradually increase complexity, and don't be afraid to break things in your development environment – that's how you learn.